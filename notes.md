# Cost function (error function / loss funtion)
* terminology - cost function (seems to be related to average over all samples) while loss or error function are denoting single training sample
* many types for different applications
# Multicolinearity
* inputs highly correlated -> network is not able to understand the influence of individual input. 
# Cleaning the data
* for instance dealing with empty data
# Normalization of data
* different nominal values of data can result in ratio of adjustments of one weight to other weight that is too big and therefore one is lets say too small.
# Linear regression vs Logistic regression
# Classification
* idea -> for binary class. only one output neuron with values form 0 to 1. For more categories -> output neuron for each of them.
* Certainties -> target values in classification (0 for not the thing as 0 %, 1 for the thing as 100 %)
* One hot encoding - for three classes, fist class is (1, 0, 0), second is (0, 1, 0), etc.
# Handy
* sigmoid function: real numbers to <0, 1>